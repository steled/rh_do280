How to Create DO280 Classrooms with Ansible

# Requirements
* IAM account for AWS
* Access to the glsdev SSH private key (in ~/.ssh/glsdev with a chmod of 0400)

It is recommended to create a Python virtual environment, however, you should
still be able to provision without one if you have access to the boto3 library.

Run the following to create a virtual environment and install the required
Python packages:

cd ~
virtualenv -p python3 venv
sudo dnf install python3-libselinux
source venv/bin/activate
pip install ansible boto boto3 botocore awscli selinux

Run deactivate when done provisioning to exit the virtual environment

# Preparation
  1. Define a guid (such as your kerberos name or nickname or random string)
  2. Copy the environment file and the secret file:
  cp do280-env_vars-sample.yml ~/do280-env_vars-{guid}.yml
  cp do280-secrets-sample.yml ~/do280-secrets-{guid}.yml

  3. Make the following change in the env_vars file
    - Change the value of 'email address'
    - Change the value of 'ocp4_installer_version' and 'oc_client_version' as
      needed

  4 .Make the following changes to the secrets file
    - Fill in all your secrets as indicated in the file
    - Leave the "Employee" pool line alone - we lookup your unique pool ID with
     "Employee SKU"

# Installation
1. Run the provision-lab.sh and deprovision-lab.sh scripts as needed.
2. Make sure you have activated your virtual environment before each run.
3. Run 'deactivate' when done.

# After the installation:
The provision-lab.sh script saves files in /tmp/do280/{guid} that you need to
access the AWS cluster and the bastion instance that lives on the same VPC.
You may want to save these files to a more permanent location, after verifying
that you new cluster is healthy.

You can login to the bastion instance using a command such as:
ssh -F /tmp/do280/{guid}/ocp4-workshop_{guid}_ssh_conf clientvm{guid}

All files generated by the OpenShift installer, including installer logs, are
saved in the /home/ec2-user/ocp-{guid} folder in the bastion instance. They are
also tarred and saved on your local /tmp/do280/{guid} folder

You can login to your new cluster using a command such as:
$ oc login -u kubeadmin -p $(cat /tmp/do280/{guid}/ocp4-workshop_{guid} \
-password) https://api.ocp-{guid}.do280.dev.nextcle.com:6443
